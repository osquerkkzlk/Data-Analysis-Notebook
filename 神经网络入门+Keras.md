# 神经网络入门 + Keras





# 1、神经网络的基本参数

损失函数指导方向，学习率控制步长，初始化器提供起点，正则化器防止过度拟合。

---

### 1. 什么是神经网络？
神经网络是一种模仿人脑神经元工作方式的计算模型，用于处理复杂的模式识别任务（如图像分类）。它由多层节点（神经元）组成，通过权重、偏置和激活函数将输入数据逐步转换为输出（预测结果）。

在您提供的代码中，神经网络用于将 32x32 像素的图像（展平为 3072 维向量）分类为特定类别（如猫、狗）。网络包含输入层、隐藏层和输出层，通过训练调整参数以提高分类准确率。

---

### 2. 激活函数
#### 定义
激活函数（Activation Function）是神经网络中每个神经元的非线性变换函数，决定该神经元是否“激活”以及输出什么值。它引入非线性，使神经网络能够解决复杂问题（如图像分类）。

#### 常见激活函数
在您的代码中使用了以下激活函数：
1. **ReLU（Rectified Linear Unit）**：
   - 公式：`f(x) = max(0, x)`
   - 作用：将负输入置为 0，正输入保持不变。简单高效，加速收敛，缓解梯度消失问题。
   - 代码示例：
     ```python
     model.add(Dense(512, activation="relu"))
     ```
   - 适用场景：隐藏层（如代码中的 512 和 256 单元层），常用于图像处理。

2. **Softmax**：
   - 公式：对于输入向量 \( x = [x_1, x_2, ..., x_n] \)，输出第 \( i \) 个类别的概率：
     $$
     \text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}
     $$
     
   - 作用：将输出转换为概率分布，总和为 1，适合多分类任务。
   - 代码示例：
     ```python
     model.add(Dense(len(lb.classes_), activation="softmax"))
     ```
   - 适用场景：输出层（如代码中用于预测类别）。

#### 其他常见激活函数
- **Sigmoid**：输出 [0, 1]，适合二分类，但易导致梯度消失。
- **Tanh**：输出 [-1, 1]，比 Sigmoid 更适合隐藏层，但计算复杂。
- **Leaky ReLU**：改进 ReLU，允许负输入有小斜率，避免“神经元死亡”。

#### 为什么需要激活函数？
- **非线性**：没有激活函数，神经网络只是线性变换，无法处理复杂模式（如图像特征）。
- **控制输出**：激活函数决定哪些神经元对结果贡献更大。

---

### 3. 全连接层
#### 定义
全连接层（Fully Connected Layer，或 Dense 层）是神经网络中一种基本层类型，其中每个输入神经元与每个输出神经元都有连接。每个连接有一个权重，输出通过激活函数处理。

#### 在代码中的体现
您的代码使用 `Dense` 层构建全连接网络：
```python
model.add(Dense(512, input_shape=(3072,), activation="relu"))
model.add(Dense(256, activation="relu"))
model.add(Dense(len(lb.classes_), activation="softmax"))
```
- **输入层**：接收 3072 维向量（32x32x3 的展平图像）。
- **隐藏层 1**：512 个神经元，每个神经元接收 3072 个输入，输出经过 ReLU 激活。
- **隐藏层 2**：256 个神经元，接收前一层的 512 个输出。
- **输出层**：神经元数等于类别数，输出概率分布。

#### 全连接层的计算
对于一个全连接层：
- 输入：向量 \( x \)（维度 \( n \)）。
- 输出：向量 \( y \)（维度 \( m \)）。
- 计算公式：
  $$
  
  y = \text{Activation}(W \cdot x + b)
  $$
  
  
  - \( W \): 权重矩阵（维度 \( m \times n \)）。
  - \( b \): 偏置向量（维度 \( m \)）。
  - \($\text{Activation}$\): 激活函数（如 ReLU 或 Softmax）。

#### 特点
- **参数多**：全连接层的参数量为 \( n \times m + m \)。例如，代码中第一层有 \( 3072 \times 512 + 512 \approx 1.57 \) 百万个参数。
- **适合简单任务**：但对图像分类，卷积层（CNN）通常更高效，因为它们捕捉空间特征。

---

### 4. 神经网络的基本参数概念
神经网络的性能和行为由以下参数和超参数控制：

#### （1）权重（Weights）
- **定义**：每个连接的强度，决定输入对输出的影响。
- **初始化**：代码中使用 `TruncatedNormal` 初始化权重（均值 0，标准差 0.05）：
  ```python
  kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=0.05)
  ```
- **作用**：通过训练调整权重以最小化损失函数。
- **优化**：权重通过反向传播和优化器（如 SGD）更新。

#### （2）偏置（Bias）
- **定义**：每个神经元的偏移量，帮助模型拟合数据。
- **初始化**：通常初始化为 0 或小值，代码中未显式指定（Keras 默认 0）。
- **作用**：增加模型灵活性，避免输出始终通过原点。

#### （3）学习率（Learning Rate）
- **定义**：控制权重更新的步长。
- **代码中**：
  ```python
  INIT_LR = 0.001
  opt = SGD(learning_rate=INIT_LR)
  ```
- **作用**：学习率太高可能导致震荡，太低则收敛慢。代码中 0.001 对于 SGD 较小，适合稳定训练。

#### （4）损失函数（Loss Function）
- **定义**：衡量模型预测与真实标签的差距。
- **代码中**：
  ```python
  model.compile(loss="categorical_crossentropy", ...)
  ```
- **分类交叉熵**（Categorical Crossentropy）：用于多分类任务，计算预测概率与真实标签的差异。
- **作用**：训练目标是最小化损失函数。

#### （5）优化器（Optimizer）
- **定义**：调整权重以最小化损失的算法。
- **代码中**：使用 SGD（随机梯度下降）：
  ```python
  opt = SGD(learning_rate=INIT_LR)
  ```
- **其他优化器**：Adam、RMSprop 等通常收敛更快，可能比 SGD 更适合图像任务。

#### （6）正则化（Regularization）
- **定义**：防止过拟合的技术。
- **代码中**：
  - **L2 正则化**：对权重施加惩罚，防止权重过大：
    ```python
    kernel_regularizer=regularizers.l2(0.01)
    ```
  - **Dropout**：随机丢弃神经元（概率 0.5），增强泛化能力：
    ```python
    model.add(Dropout(0.5))
    ```

#### （7）Epoch 和 Batch Size
- **Epoch**：整个训练数据集经过一次前向和反向传播的次数。代码中：
  ```python
  EPOCHS = 2000
  ```
  - 2000 可能过多，建议用早停机制。
- **Batch Size**：每次训练处理的样本数。代码中：
  ```python
  batch_size=32
  ```
  - 32 是常见选择，平衡内存和收敛速度。

#### （8）评估指标（Metrics）
- **定义**：衡量模型性能的指标。
- **代码中**：
  
  ```python
  model.compile(..., metrics=["accuracy"])
  ```
- **准确率**（Accuracy）：预测正确的样本比例。
- **分类报告**：提供精确率、召回率、F1 分数：
  ```python
  print(classification_report(...))
  ```

---

#### 5、结合代码的例子

以下是代码中神经网络的结构和参数如何协同工作：
1. **输入**：32x32 像素 RGB 图像，展平为 3072 维向量。
2. **第一层（Dense 512, ReLU）**：
   - 输入 3072 维，输出 512 维。
   - 参数量：\( 3072 \times 512 + 512 \approx 1.57 \) 百万。
   - ReLU 激活：将负值置为 0。
   - Dropout (0.5)：随机丢弃 50% 的输出。
3. **第二层（Dense 256, ReLU）**：
   - 输入 512 维，输出 256 维。
   - 参数量：\( 512 \times 256 + 256 \approx 0.13 \) 百万。
4. **输出层（Dense num_classes, Softmax）**：
   - 输出类别数的概率分布。
   - 例如，若有 3 个类别，参数量为 \( 256 \times 3 + 3 = 771 \)。

**训练过程**：
- 使用 SGD 优化器，学习率 0.001，更新权重以最小化分类交叉熵损失。
- 每 32 个样本（batch_size）更新一次权重，重复 2000 次（epochs）。
- L2 正则化和 Dropout 防止过拟合。

---

#### 6、常见问题解答

1. **为什么不用卷积层？**
   - 您的代码使用全连接层，适合简单任务，但对图像分类，卷积神经网络（CNN）更高效，因为它们捕捉空间特征。CNN 使用 `Conv2D` 层，参数量更少，效果更好。

2. **如何选择激活函数？**
   - 隐藏层：ReLU 是默认选择，简单高效。
   - 输出层：多分类用 Softmax，二分类用 Sigmoid。

3. **如何调整参数？**
   - **学习率**：尝试 0.01 或 0.0001，观察收敛。
   - **正则化**：L2 的 0.01 可能过强，试 0.001。
   - **Epoch**：使用早停（EarlyStopping）自动选择最佳 epoch。

4. **全连接层的局限性？**
   - 参数量大（代码中约 1.7 百万参数），计算成本高。
   - 对图像的空间结构不敏感，建议用 CNN。

---

### 5、激活函数的选取

激活函数是神经网络中引入非线性的关键元素，它们使网络能够学习复杂的模式。下面是深度学习中最常用的激活函数及其特点：

#### ReLU (修正线性单元)

**函数表达式**：f(x) = max(0, x)

**特点**：

- 计算效率高，仅需简单的阈值操作
- 对于正输入可以缓解梯度消失问题
- 产生稀疏激活（许多神经元输出为0），这可能有益于模型
- 在x=0处不可微，但实际应用中很少造成问题
- 隐藏层中最广泛使用的激活函数
- 输出范围：[0, ∞)

**局限性**：

- "死亡ReLU"问题 - 当神经元持续接收负输入时，可能永久性失活
- 输出不以零为中心，可能导致训练过程中的锯齿状动态

#### Leaky ReLU (渗漏ReLU)

**函数表达式**：f(x) = max(αx, x)，其中α通常是一个小值，如0.01

**特点**：

- 通过允许负输入有小梯度来解决死亡ReLU问题
- 保留ReLU的大部分计算优势
- 输出范围：(-∞, ∞)
- 除x=0外处处可微（与ReLU类似）

#### PReLU (参数化ReLU)

**函数表达式**：与Leaky ReLU类似，但α是一个可学习参数

**特点**：

- 允许模型学习负值的最佳斜率
- 可以适应数据，潜在地提高性能
- 比固定α值的Leaky ReLU更灵活

#### ELU (指数线性单元)

**函数表达式**：f(x) = x if x > 0 else α(e^x - 1)

**特点**：

- 对负值有软饱和效应，使其对噪声更鲁棒
- 输出均值接近于零，有助于加速学习
- 在所有点都可微
- 计算成本高于ReLU

#### SELU (缩放指数线性单元)

**函数表达式**：f(x) = λx if x > 0 else λα(e^x - 1)

**特点**：

- 自归一化性质，有助于深层网络的训练稳定性
- 被设计用来保持输入和输出的均值和方差
- 在某些情况下可以不使用批量归一化

#### Sigmoid

**函数表达式**：f(x) = 1 / (1 + e^(-x))

**特点**：

- 输出范围为(0, 1)，可解释为概率
- 在二元分类问题的输出层常用
- 处处可微
- 在输入绝对值较大时会饱和，导致梯度几乎为零

**局限性**：

- 容易引起梯度消失问题
- 输出不以零为中心
- 计算指数函数较为昂贵

#### Tanh (双曲正切)

**函数表达式**：f(x) = (e^x - e^(-x)) / (e^x + e^(-x))

**特点**：

- 输出范围为(-1, 1)，以零为中心
- 比Sigmoid在隐藏层表现更好
- 处处可微
- 仍然存在饱和问题

#### Softmax

**函数表达式**：f(x_i) = e^(x_i) / Σ(e^(x_j))，对所有j求和

**特点**：

- 将输入转换为概率分布（所有输出之和为1）
- 多分类问题输出层的标准选择
- 强调最大值，抑制其他值
- 与交叉熵损失函数配合良好

### 6、compile

在深度学习中，`compile()`是模型训练前的关键准备步骤，相当于为神经网络设置学习规则和目标。我来深入解释这个函数的作用、参数和内部机制。

#### compile()方法的本质

`compile()`方法本质上是在告诉模型三件重要的事：

1. 如何测量成功与失败（损失函数）
2. 如何改进自己（优化器）
3. 关注哪些性能指标（评估指标）

这就像是给学生制定学习计划：你需要知道考试如何评分（损失函数），采用什么学习方法（优化器），以及除了考试成绩外还要关注哪些能力的提升（评估指标）。

#### 主要参数详解

##### 1. 损失函数 (loss)

损失函数定义了模型预测值与真实值之间的差距计算方法。常见选项包括：

- `categorical_crossentropy`：适用于多分类问题，目标是one-hot编码形式
- `sparse_categorical_crossentropy`：也用于多分类，但目标是整数标签而非one-hot向量
- `binary_crossentropy`：二元分类问题的标准选择
- `mean_squared_error`：回归问题的常用损失函数
- `mean_absolute_error`：对异常值不那么敏感的回归损失函数

每种损失函数都有其适用场景。例如，你的代码中使用的`categorical_crossentropy`专为多类别分类设计，非常适合与softmax激活函数配合使用。

##### 2. 优化器 (optimizer)

优化器决定了如何基于损失函数的梯度更新模型权重。常见的优化器包括：

- `SGD`：最基础的随机梯度下降，可以配置动量和学习率衰减
- `Adam`：自适应学习率的优化器，结合了动量和RMSprop的优势
- `RMSprop`：自适应学习率方法，适合处理非平稳目标
- `Adagrad`：为不同参数自动调整学习率的方法

##### 3. 评估指标 (metrics)

评估指标用于监控训练和测试过程。与损失函数不同，它们通常不用于梯度更新，而是为了提供更直观的性能度量：

- `accuracy`：分类准确率
- `precision`：精确率
- `recall`：召回率
- `AUC`：ROC曲线下面积
- `mae`：平均绝对误差（回归问题）

这些指标会在训练期间定期计算并显示，帮助你了解模型学习进展。

#### compile()内部工作机制

当你调用`compile()`时，Keras会：

1. **构建计算图**：根据你的损失函数和优化器设置，准备好用于前向和反向传播的计算路径
2. **准备梯度计算**：设置自动微分所需的内部状态
3. **优化器初始化**：初始化优化器所需的状态变量（如动量缓存等）
4. **确定输出格式**：根据损失函数和度量指标，确定模型应输出什么样的预测结果

这就像是一位教练在训练开始前，确定训练计划、评价标准和改进策略。

#### compile()与fit()的区别

很多初学者会混淆`compile()`和`fit()`这两个函数：

- `compile()`是训练前的准备工作，定义学习规则
- `fit()`是实际执行训练的函数，将数据喂给模型并迭代更新权重

换句话说，`compile()`设定目标和方法，而`fit()`则是做实际工作的函数。

#### 一个类比：烹饪过程

想象你要烹饪一道菜：

- 构建模型（定义网络结构）相当于准备食材和厨具
- `compile()`相当于选择食谱和烹饪方法
- `fit()`相当于实际的烹饪过程

没有正确的`compile()`设置，模型就无法有效学习，就像没有清晰的食谱，再好的食材也难以做出美味佳肴。

#### 在你代码中的具体应用

```python
model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
```

这行代码告诉你的神经网络：

- 使用分类交叉熵来衡量预测错误（适合多分类问题）
- 使用前面创建的SGD优化器来更新权重
- 除了损失值外，还要跟踪和报告准确率这一指标

这些设置与你模型的结构紧密相关：最后一层使用softmax激活函数，刚好与categorical_crossentropy损失函数匹配；而accuracy度量指标则适合分类任务的评估。

### 7、fit

`model.fit()` 方法是实际开始训练神经网络的命令，它启动了迭代学习过程，数据在网络中不断前向传播和反向传播，逐步调整权重以最小化损失函数。这个函数的工作原理可以比作一个学生通过反复练习和修正来掌握知识点。

#### 主要参数解释

1. **trainX, trainY**： 这是训练数据和对应的标签。`trainX` 包含输入特征（比如图像像素值），而 `trainY` 包含目标输出（比如类别的one-hot编码）。模型将学习从 `trainX` 到 `trainY` 的映射关系。
2. **validation_data=(testX, testY)**： 这是用于验证的数据集和标签，模型不会用它们来学习（调整权重），而是用来评估当前模型的泛化能力。验证集就像是"模拟考试"，帮你检验学习效果但不会直接影响学习过程。
3. **epochs=EPOCHS**： 轮次数，表示整个训练数据集被完整处理的次数。每个轮次，模型会查看所有训练样本一次。如果 `EPOCHS=20`，意味着整个训练集会被处理20次。这就像学生反复复习教材20遍，每遍都能加深理解。
4. **batch_size=32**： 批量大小，表示一次更新模型参数前处理的样本数。这里设置为32意味着模型会看32个样本，计算它们的平均梯度，然后更新一次参数。较大的批量提供更稳定但可能较慢的学习；较小的批量学习更快但波动更大。

#### 返回值 H

`H = model.fit(...)` 中的 `H` 是一个历史对象（History），它记录了训练过程中每个轮次（epoch）的损失值和指标值（如准确率）。H 是 model.fit 的返回值（History 对象），H.history 是一个字典，包含训练过程中的指标：

- "accuracy"：训练集准确率（每 epoch 的值）。
- "val_accuracy"：验证集准确率。
- "loss"：训练集损失（注释中未用）。
- "val_loss"：验证集损失（注释中未用）。

#### model.fit() 内部工作机制

当你调用 `model.fit()` 时，以下是内部发生的事情：

1. **数据准备**：将数据分成指定大小的批次

2. 对于每个轮次（epoch）

   ： a. 

   对于每个批次

   ：

   - 前向传播：输入数据通过网络，生成预测
   - 计算损失：比较预测与真实标签
   - 反向传播：计算梯度
   - 参数更新：优化器根据梯度更新权重 b. 完成所有批次后，在验证集上评估模型 c. 显示该轮次的训练和验证指标（损失值、准确率等） d. 更新历史对象

这就像学生的学习过程：阅读一些材料（批次）→ 尝试理解 → foo测验自己 → 调整理解方式 → 重复，直到完成整本书（一个轮次）→ 进行模拟考试（验证）→ 开始下一轮学习。

#### 一个深入的类比：驾驶培训

想象 `model.fit()` 就像学开车的过程：

- **训练数据**（trainX/trainY）是你练习的各种道路和正确的驾驶方式
- **验证数据**（testX/testY）是模拟考试路线
- **epochs** 是你练习驾驶的天数
- **batch_size** 是每次练习连续开车的时间（比如32分钟）
- **前向传播**是你的实际驾驶尝试
- **损失计算**是教练指出你的错误
- **反向传播和参数更新**是你根据反馈调整驾驶习惯
- **历史对象H**是记录你每天进步情况的学习日志

随着练习天数增加，你的驾驶技能应该提高，错误减少，但如果只在固定路线上反复练习（过拟合），在新路线（测试数据）上的表现可能不佳。

#### fit() 在深度学习工作流中的位置

在典型的深度学习工作流程中：

1. 准备数据（加载、预处理、划分训练/验证集）
2. 构建模型（定义层、激活函数等）
3. 编译模型（设置损失函数、优化器、指标）
4. **训练模型**（使用 `model.fit()`）← 你的代码在这里
5. 评估模型（在测试集上验证性能）
6. 预测和应用（部署模型进行实际预测）

`model.fit()` 是耗时最长、计算最密集的步骤，在大型数据集上可能需要数小时甚至数天。

#### 训练过程的监控和调整

当 `model.fit()` 运行时，你通常会看到如下输出：

```
Epoch 1/20
500/500 [==============================] - 2s 4ms/step - loss: 2.1847 - accuracy: 0.3254 - val_loss: 1.8932 - val_accuracy: 0.4102
Epoch 2/20
500/500 [==============================] - 2s 4ms/step - loss: 1.7539 - accuracy: 0.4872 - val_loss: 1.6243 - val_accuracy: 0.5230
...
```

这些输出告诉你：

- 当前轮次进度
- 训练损失和准确率
- 验证损失和准确率
- 每步（批次）处理时间

通过观察这些数值，你可以：

1. 确认模型正在学习（损失值下降）
2. 检测过拟合（训练指标改善但验证指标恶化）
3. 决定是否提前停止训练（验证指标停止改善）

### 8、predict 和 classification_report

这段代码是深度学习项目中的模型评估阶段，用于测试训练好的模型在未见数据上的表现并生成详细的性能报告。

```python
predictions = model.predict(testX, batch_size=32)
```

这行代码使用训练好的模型对测试数据进行预测。`model.predict()`函数接收测试数据`testX`，并返回模型的预测结果。与训练阶段类似，这里也设置了`batch_size=32`，表示一次处理32个样本，这样可以高效利用计算资源，特别是当测试数据量较大时。

返回的`predictions`是一个概率矩阵，其中每行对应一个测试样本，每列对应一个类别的预测概率。例如，如果有3个类别，一个样本的预测结果可能是[0.1, 0.7, 0.2]，表示模型认为这个样本有70%的概率属于第二类。

```python
print(classification_report(testY.argmax(axis=1),
    predictions.argmax(axis=1), target_names=lb.classes_))
```

这行代码生成并打印一个详细的分类报告，对模型性能进行全面评估。让我们分解其参数：

1. `testY.argmax(axis=1)`：将one-hot编码的真实标签转换回类别索引。例如，[0,1,0]变成1，表示第二类。
2. `predictions.argmax(axis=1)`：同样地，将模型预测的概率向量转换为类别索引，选择概率最高的类别。
3. `target_names=lb.classes_`：指定类别的名称，而不是仅显示索引号，使报告更具可读性。`lb.classes_`来自于标签二值化器（LabelBinarizer），包含了所有类别的名称。

#### 分类报告的理解

`classification_report`函数生成的报告包含以下关键指标：

1. **精确率(Precision)**：预测为某类的样本中，真正属于该类的比例。
   - 公式：TP/(TP+FP)
   - 高精确率意味着低误报率（很少将其他类错误地识别为此类）
2. **召回率(Recall)**：真正属于某类的样本中，被正确预测为该类的比例。
   - 公式：TP/(TP+FN)
   - 高召回率意味着低漏报率（很少漏掉真正属于此类的样本）
3. **F1分数**：精确率和召回率的调和平均值，提供了一个平衡的性能指标。
   - 公式：2 * (precision * recall) / (precision + recall)
   - 当类别不平衡时，F1比简单的准确率更有意义
4. **支持度(Support)**：每个类别的测试样本数量，帮助理解数据分布
5. **准确率(Accuracy)**：整体正确预测的比例，报告末尾会给出
6. **加权平均(Weighted Avg)**：考虑了各类别样本数量的指标平均值

#### 一个形象的类比

想象你是一位医生，使用一个诊断系统来判断患者是否患有某种疾病：

- **精确率** 回答的是："系统诊断为阳性的患者中，有多少真的患病？"这关系到不必要的治疗和焦虑。
- **召回率** 回答的是："真正患病的人中，系统能识别出多少？"这关系到漏诊的严重后果。
- **F1分数** 帮助你在这两者之间找到平衡点，特别是当疾病稀有但漏诊成本高时。

#### 实际输出示例及理解

分类报告的输出可能如下所示：

```
              precision    recall  f1-score   support

        猫       0.92      0.88      0.90       100
        狗       0.85      0.91      0.88       100
        鸟       0.94      0.82      0.88        50

    accuracy                          0.88       250
   macro avg       0.90      0.87      0.88       250
weighted avg       0.89      0.88      0.88       250
```

从这个报告中，我们可以得出以下洞见：

- 模型在识别猫时精确率很高(0.92)，意味着当它说"这是猫"时，大概率是对的
- 但它的召回率稍低(0.88)，表明有些猫被错误地归类为其他动物
- 对于狗，情况相反：召回率高(0.91)但精确率低(0.85)，意味着模型倾向于将其他动物误判为狗
- 鸟类有最高的精确率(0.94)但最低的召回率(0.82)，表明模型非常谨慎地预测鸟类，但因此会漏掉一些真正的鸟

### 9、卷积神经网络 CNN

这是卷积神经网络 (CNN) 的简短精辟流程：

1. **卷积 (Convolution):** 提取图像特征（边缘、纹理等）。
2. **激活 (Activation):** 引入非线性，使网络学习复杂模式（常用 ReLU）。
3. **池化 (Pooling):** 减小特征图尺寸，降低计算复杂度。
4. **重复 1-3:** 多次堆叠，逐层提取更抽象的特征。
5. **展平 (Flatten):** 将多维特征图转为一维向量。
6. **全连接 (Fully Connected):** 像传统神经网络一样，进行分类或回归。
7. **输出 (Output):** 得到最终结果（类别概率等）。



# 2、kreas

## 1.超参数优化

**Keras Tuner 简介**

Keras Tuner 是一个专为 TensorFlow/Keras 设计的超参数优化库，简化了模型超参数和架构的调优，支持随机搜索、贝叶斯优化和 Hyperband 算法。适用于优化学习率、层数、神经元数量等。

---

### **核心功能**
- **超参数定义**：
  - `hp.Int(name, min, max, step)`：整数型（如层数、神经元数）。
  - `hp.Float(name, min, max, sampling='linear'/'log')`：浮点型（如学习率）。
  - `hp.Choice(name, values)`：离散值（如激活函数 ['relu', 'tanh']）。
  - `hp.Boolean(name)`：布尔值（如是否使用 Dropout）。
- **条件超参数**：通过 `hp.ConditionalScope` 定义参数依赖。
- **优化算法**：
  - **RandomSearch**：随机采样超参数。
  - **BayesianOptimization**：基于概率模型高效搜索。
  - **Hyperband**：动态分配资源，优先评估高潜力配置。
- **目标指标**：优化验证集指标（如 `val_accuracy`、`val_loss`）或自定义指标。
- **早停支持**：结合 `EarlyStopping` 回调减少无效试验。

---

### **使用步骤**
1. **定义模型**：创建函数 `build_model(hp)`，用 `hp` 指定超参数。
2. **初始化 Tuner**：
   ```python
   tuner = kt.Hyperband(build_model, objective='val_accuracy', max_epochs=10, directory='my_dir', project_name='tune')
   ```
3. **搜索**：`tuner.search(X, y, validation_data=(X_val, y_val), epochs=50)`。
4. **获取结果**：
   - 最佳超参数：`tuner.get_best_hyperparameters()[0].values`。
   - 最佳模型：`tuner.get_best_models()[0]`。

---

### **关键参数**
- **Tuner 初始化**：
  - `objective`：优化目标（如 `'val_accuracy'`）。
  - `max_epochs`：最大训练轮次（Hyperband 专用）。
  - `max_trials`：最大试验次数（RandomSearch/Bayesian）。
  - `executions_per_trial`：每组超参数重复试验次数，减少随机性。
  - `directory/project_name`：保存搜索结果。
- **搜索方法**：
  - `search(X, y, epochs, validation_data, callbacks)`：支持早停、自定义回调。

---

### **安装**
```bash
pip install keras-tuner
```

---

### **简短示例**
```python
import keras_tuner as kt
import tensorflow as tf
from tensorflow import keras

def build_model(hp):
    model = keras.Sequential([
        keras.layers.Dense(hp.Int('units', 32, 128, step=32), activation='relu'),
        keras.layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=keras.optimizers.Adam(hp.Float('lr', 1e-4, 1e-2, sampling='log')),
                  loss='binary_crossentropy', metrics=['accuracy'])
    return model

tuner = kt.Hyperband(build_model, objective='val_accuracy', max_epochs=10)
tuner.search(X_train, y_train, validation_data=(X_val, y_val), epochs=50)
best_model = tuner.get_best_models()[0]
```

---

### **优点**
- 简单易用，集成 TensorFlow/Keras。
- 灵活支持多种优化算法。
- 可扩展至复杂模型（如 CNN、RNN）。

### **资源**
- 官方文档：https://keras.io/keras_tuner/
- GitHub：https://github.com/keras-team/keras-tuner
- TensorFlow 教程：https://www.tensorflow.org/tutorials/keras/keras_tuner



## 1、张量 tensor

#### 张量是矩阵向任意维度的推广。

1. 仅包含一个数字的张量叫做标量，或者0D张量。张量轴的个数也叫做阶数 `rank`。

2. 数字组成的数组叫做向量，或者1D张量。
3. 向量组成的数组叫做矩阵，或者2D张量

#### 张量的关键属性

轴的个数（阶），形状，数据类型

#### 张量运算

1、张量变形：改变张量的额行和列，以得到想要的形状。变形后的张量的元素总个数和之前一样。

2、张量点积：A@B

## 2、广播

**广播（Broadcasting）**是指在进行数组或张量运算时，**自动扩展维度**以便形状不一致的数据能进行运算的机制。

------

#### 简化理解：

当两个形状不同的数组进行操作时，系统会**自动复制较小数组的维度**，使它们形状一致，再执行逐元素操作。

------

#### NumPy 例子：

```python
import numpy as np

a = np.array([1, 2, 3])
b = 2
print(a + b)  # 输出: [3 4 5]
```

`b` 被广播为 `[2, 2, 2]`，然后与 `a` 相加。

------

广播让你**无需手动调整形状**，简化了代码逻辑。

## 3、处理标签和损失

编码标签的方法有两种，一种是分类编码，e.g `to_categorical	` ,相对应的损失函数就应该是 `categorical_crossentropy` ；另一种是整数编码 ，但需要利用numpy将标签转换为张量，相对应的损失函数就是 `sparse_categorical_crossentropy`

## 4、经验之谈

1、中间隐藏层的神经元个数如果比较小，很容易引起信息瓶颈，前一层网络将信息传入该层时，由于神经元数量受限，导致传入信息不完整，导致训练出的模型精度下降。

2、如果神经网络最后一层是纯线性的，没有激活函数，网络可以学会预测任意范围中的值。

3、如果输入数据的特征具有不同的取值范围，应该先进行预处理，即标准化。

4、如果可用的数据很少，可以采用k折交叉验证法。

5、评估模型时，要保证数据具有代表性，在划分训练集和测试集之前，通常应该随机打乱数据，并且要保证训练集和验证集之间没有交集。

6、数据预处理中，神经网络的输入和目标都必须是浮点数张量(有些情况下可以为整数张量)，需要对数据进行标准化，也需要注意缺失值。

## 5、evaluate评估模型

------

#### **1. 在机器学习中：`evaluate()` 的作用**

这是**评估模型在新数据上的表现**，通常用于验证模型是否泛化良好。

例子（Keras）：

```python
loss, accuracy = model.evaluate(x_test, y_test)
print("测试损失：", loss)
print("测试准确率：", accuracy)
```

- `x_test`: 输入测试数据
- `y_test`: 对应的真实标签
- `loss`: 模型在测试集上的损失值（越小越好）
- `accuracy`: 模型在测试集上的预测准确率（越高越好）

------

#### **2. 为什么用 `evaluate()`？**

- 训练后检查模型效果
- 防止过拟合（仅在训练集上好不算好）
- 用于模型对比（哪个模型在测试集上表现最好）

#### **3. 对比训练与评估**

| 操作         | 目的             | 使用的数据       |
| ------------ | ---------------- | ---------------- |
| `fit()`      | 训练模型         | 训练数据         |
| `evaluate()` | 评估模型性能     | 验证/测试数据    |
| `predict()`  | 输出模型预测结果 | 新的未知输入数据 |

## 6、过拟合与欠拟合

机器学习的根本问题是优化与泛化的对立。优化是指调节模型以在训练数据上得到最佳性能，而泛化则是指训练好的模型在前所未见的数据上的性能的好坏，实际上我们往往需要解决过拟合的问题。下面是一些方法

#### 1、减少网络容量

#### 2、添加权重正则化

**也就是强制让模型权重只能取较小的值。从而限制模型的复杂度，这使得权重的分布更加规则**

------

🔧 常见的两种权重正则化方法：

| 名称          | 数学形式   | 常见名称 | 作用说明                     |
| ------------- | ---------- | -------- | ---------------------------- |
| **L1 正则化** | `λ * Σ     | w        | `                            |
| **L2 正则化** | `λ * Σ w²` | Ridge    | 抑制过大的权重，更稳定、常用 |

其中 `λ` 是正则化强度，`w` 是模型的权重。

------

✅ Keras 示例（使用 L2 正则化）：

```python
from tensorflow.keras import regularizers
from tensorflow.keras.layers import Dense

Dense(64, activation='relu',
      kernel_regularizer=regularizers.l2(0.01))  # L2 正则项
```



------

📌 小结

| 正则化类型 | 关键目的               | 是否常用 |
| ---------- | ---------------------- | -------- |
| L1         | 稀疏权重（特征选择）   | 中等     |
| L2         | 抑制大权重（平滑模型） | 非常常用 |

---

#### 3、 dropout正则化

对某一层使用dropout，就是在训练过程中随机将该层的一些输出特征舍弃（置为0），dropout比率就是被设为0的特征所占的比例

#### 4、获取更多的训练数据



## 7、数据处理

#### 1、卷积网络与全连接网络 对比

Dense层从输入特征空间中学到的是全局模式，而卷积层学习到的是局部模式。这就使得神经网络学到的模式具有平移不变性，卷积完网络学习了某个模式，它可以在全局任何位置识别这个模式。而全连接网络只能重新学习这个模式。另一方面，卷积神经网络可以学习模式的空间层次结构，这时深度轴的通道不再像RGB那样代表特定的颜色，而是代表滤波器。

#### 2、最大池化操作 MaxPooling

利用池化操作来进行下采样的原因，一是减少需要处理的特征图的元素个数，二是通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例会越来越大），从而引入空间过滤器的层级结构

####  3、数据预处理

图像处理辅助工具模块 `ImageDataGenerator`

```python
from keras.preprocessing.image import ImageDataGenerator

datagen=ImageDataGenerator(rescale=1./255)
gengerator=datagen.flow_from_directory(
					path,
					target_size=(150,150),
					batch_size=32,
					class_mode="binary")
...
# 利用生成器来训练模型
history = model.fit(
			gengerator,
			steps_per_epoch=100,
			epochs=100,
			validation_data=val_gengerator,
			validation_steps=50)
```

✨ImageDataGenerator进行数据增强  常用的数据增强参数：

| 参数名               | 作用                     |
| -------------------- | ------------------------ |
| `rotation_range`     | 随机旋转角度（0~指定角） |
| `width_shift_range`  | 水平平移（比例或像素）   |
| `height_shift_range` | 垂直平移                 |
| `shear_range`        | 剪切变换角度             |
| `zoom_range`         | 随机缩放                 |
| `horizontal_flip`    | 随机水平翻转             |
| `fill_mode`          | 填充方式（如 'nearest'） |

------

✅ 示例代码：

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 定义数据增强
train_datagen = ImageDataGenerator(
    rescale=1./255,                  # 归一化
    rotation_range=20,              # 随机旋转
    width_shift_range=0.2,          # 水平平移
    height_shift_range=0.2,         # 垂直平移
    zoom_range=0.2,                 # 随机缩放
    horizontal_flip=True,           # 水平翻转
    fill_mode='nearest'             # 边界填充
)

# 加载图片数据
train_generator = train_datagen.flow_from_directory(
    'data/train',                   # 图像所在目录
    target_size=(150, 150),         # 调整大小
    batch_size=32,
    class_mode='categorical'        # 多分类
)
```

------

🎯 用法总结

- 训练数据增强只用在训练集，不用于验证/测试集

- 它是**边训练边增强**（实时生成），不会生成新文件

- 搭配 `model.fit(train_generator)` 使用即可

  

## 8、预训练的卷积神经网络

预训练网络是一个保存好的网络，之前已经在大型数据集上训练好。使用预训练网络的方法有特征提取和微调模型。

#### 1、特征提取

特征提取是使用之前网络学到的表示来从新样本中提取出的有趣的特征，然后将这些特征输入到一个新的分类器中。

📌 

- 预训练模型提取的特征很通用（比如边缘、结构、语义）
- 节省计算资源，不用从头训练深度网络
- 即使数据少，也能有不错的效果

卷积基学到的表示可能更加通用，因此更适合重复使用。卷积神经网路的特征图表示通用概念在图像中是否存在，是通用的。但是分类器学到的表示是针对于模型训练的类别，其中仅包含某个类别的概率信息，丢失了空间的概念。

值得注意的是，某个卷积层提取的表示的通用性以及可复用性，取决于该层在1模型中深度。模型中更靠近底部的层提取的特征是局部的，比如边缘、颜色、纹理等。而更靠近顶部的层提取的是更加抽象的概念，比如“猫耳朵”，因此如果新的数据集和原先训练的数据集差异比较大的话，最好使用前几层来进行特征提取，而不是选用整个卷积基。

==在这里，更靠近底部的层是指先被添加进模型中的层。==

数据增强的特征提取是指扩展卷积基，你需要将convbase的trainable属性设置为False，保证其在训练过程中参数权重不发生改变，并且这个操作应该在compile之前生效。 关键点：**数据增强 = 训练时实时变化**，但预训练卷积基如果不训练，根本“感知不到这些变化”。

------

🔍 分情况解释：

------

❌ 情况 1：**冻结卷积基，只用于提特征**

- 做法：你把卷积层当作固定特征提取器

  ```python
  conv_base.trainable = False
  ```

- 只对每张图像“提一次特征”

- 数据增强在这里没意义，因为增强图像**不会传递到训练过程**（特征已经提完了）

#### 🧨 举个比喻：

> 你给模型准备了各种不同版本的图像（旋转、缩放）
>  但你只提一次特征 → 模型根本没“看到”这些变化

------

✅ 情况 2：**扩展模型、微调卷积基（fine-tune）**

- 卷积基继续训练 → 每次看到的增强图像都能更新权重
- 增强图像 → 训练更稳健、抗干扰能力更强
- 数据增强能**真正帮助模型学习**

**只有当卷积基参与训练（即扩展/微调时）**，增强数据的“变化”才会传递到模型中，帮助它学得更鲁棒。 如果只是“提特征”，增强图像再多也没用，因为模型只看了一次静态图像。

#### 2、模型微调

将卷积层顶部的几个层解冻，让他们一起参与训练，但应该把优化器的学习率设置的小一点。 



## 9、深度学习用于处理文本和实践序列

#### 1、基本概念

1. 标记：将文本分解而成的单元（单词、字符、序列）叫做标记（token）
2. 分词：将文本分解成标记的过程叫做分词
3. 将向量与标记关联主要有两种方法，one-hot编码和词嵌入，one-hot编码得到的向量是稀疏的（绝大部分元素为0），二进制的，而词嵌入是地位的浮点数向量（即密集的向量），可以将更多信息塞入更低维度中。

#### 2、常见内置方法

```python
preprocessing.sequence.pad_sequences(data,maxlen=100)
# 将整数列表转换成形状为 (samples,maxlen)

Embedding(10000,8,input_length=maxlen)
# 指定Embedding层最大输入长度，一边后面将嵌入输入展平。Embedding层的激活形状为
# (samples,maxlen,Embedding_dim)

```

#### 3、词嵌入

```python
model.layers[0].set_weights(embdedding_matrix)
model.layers[0].trainable=False
```

与卷积网络类似，使用预训练的词嵌入矩阵时，我们需要设置Embedding层的权重为我们构建好的矩阵，并且需要将其冻结，使模型在训练过程中权重不会发生改变。

#### 4、简单循环神经网络（SimpleRNN）

遍历所有的序列元素并保存一个状态，与前馈网络（FFNN）不同，RNN会对序列内部元素进行遍历。在keras中，`RNN`实际上对应着`SimpleRNN`。SimpleRNN层能够像keras中的其他层一样处理序列批量，因此他的接受形状为（batch_size,timesteps,input_features）。SimpleRNN可以在两种不同的模式下运行：一种是返回每个时间不连续输出的完整序列，即形状为（batch_size , timeseps , output_features）的三位张量，另一种是只返回每个输入序列的输出，即形状为（batch_size , output_features）的二维张量。这两种模式由return_sequences这个构造函数来控制。一般而言中间RNN层保持这个参数为`True`，即返回完整的时间序列，并让最后一层为False（default），只输出最终的结果。

但是SImple RNN存在梯度消失问题，随着训练层数的增加，网络最终会无法训练

#### 5、长短期记忆网络（LSTM）

增加了一条平行于序列的“传送带”，序列中的信息可以在任意位置跳上“传送带”，然后被传到更晚的时间步，当需要时又会原封不动地跳回来。LSTM适合评论全局的长期性结构

#### 6、门控循环单元（GRU）

`GRU`利用了数据点地时间顺序，工作原理和`LSTM`类似，但做了一些简化，计算代价更低。

#### 7、利用`循环dropout`降低过拟合

keras的每个循环层都有两个与dropout相关的参数：一个是dropout，他是一个浮点数，指定该层输入单元的dropout比率；另一个是recurrent_dropout，指定循环单元的dropout比率。

#### 8、循环层堆叠

增加网络容量的通常做法是增加每层单元数或增加层数。循环曾堆叠可以构建更加强大的循环网络。在keras中诸葛堆叠循环曾，所有中间层都因该返回完整的输出序列（3D张量），而不是只返回最后一个时间步的输出。这个操作可以通过`return_sequences`来实现

#### 9、双向RNN

双向RNN利用了RNN的顺序敏感性：它包括两个RNN，分别从正序和逆序去处理序列，然后将他们合并在一起。值得注意的是，在一个文本数据集上，逆序处理的效果和正序处理的效果一样好，也就是说：单词顺序对理解语言很重要，但是用哪种顺序并不重要。逆序为机器提供了一种观察任务的全新视角，会捕捉到正序RNN所忽略的一些细节。

```python
model.add(layers.Bidirectional(LSTM(32)))
```

#### 10、一维卷积网络处理序列

卷积运算能从局部输入图块中提取特征，Conv1D接收的输入形状为（samples,time,features）的三维张量。一维卷积网络可以分别处理每个输入序列段，所以他对时间顺序不敏感。同时卷积神经网络在输入时间序列的所有位置寻找模式，呀并不知道所看到的某个模式的时间位置（距开始多长时间，距结束多长时间）。

使用它的技巧是：处理时间序列时，先对他进行卷积，提取特征，之后使用循环神经网络处理序列数据。通常将Conv1D和MaxingPooling1D堆叠咋一起，最后加上一个全局池化操作GlobalMaxPooling1D。如果整体顺序没有那么重要，单独使用一维卷积网络也是可以的。



## 10、深度学习高级操作

#### 1、函数式api

Sequential模型是单输入单输出的线性模型，有时满足不了需要，我们可以使用多输入多输出的Model模型。需要注意的是，严重不平衡的损失贡献会导致模型会针对单个损失最大的任务优化先进性优化，所以我们可以加入损失权重来解决这个问题。

#### 2、共享层权重

层定义一次，但使用多次，每次调用都会相同的权重。

```python
lstm=LSTM(32)
left_output=lstm(left_input)
right_output=lstm(right_input)      
```

#### 3、类标准化

类标准化可以让机器学习模型看到的不同的样本之间批次更加相似，有助于模型的学习与对新数据的泛化。把数据缩放成高斯分布，是数据输入的常用处理手段。批标准化让数据适应性地将数据标准化，有助于梯度上升，在keras中是`BatchNormialization`，该层会接受一个axis参数，表示它对哪一个轴进行表转化，默认是-1，即输入张量的最后一个轴。

#### 4、深度可分离卷积

深度可分离卷积具有更轻便，速度更快的优点，即SeparableConv2D。该层会对输入的每个通道分别执行空间卷积，然后通过逐点卷积（1  x  1点积）将输出通道混合，相当于把空间特征学习和通道特征学习分开。如果输入中的空间位置高度相关，但不同通道之间相对独立，这种方法是很有用的

==深度可分离卷积 = 每个通道先自己卷积（空间提取） + 通道之间再融合（通道提取）==



## 11、深度学习概况

深度学习是机器学习的分支之一。他的模型是一长串的几何函数一个接一个地作用在数据上。这些运算被组织成模块，叫做层。深度学习模型通常是层的堆叠。这些层由权重初始化，权重是在训练过程中需要学习的参数，模型的只是保存在他的权重中，学习的该过程就是为这些权重找到恰当的值。

在深度学习中，一切都是几何空间中的点。首先将模型输入和目标向量化，即将其转换为初始输入向量空间和目标向量空间。深度学习模型的每一层都对通过他的数据做一个简单变换。模型的层链可以被分解为一系列的简单的几何变换。这个复杂变换试图将输入空间映射到目标空间，每次映射一个点。这个变换由层的权重参数化。权重根据当前的表现进行迭代更新。这个几何变换有一个关键性质，就是它必须是可微的，这样我们才能通过梯度下降来学习其参数。直观上看，==这意味着从输入到输出的几何变形必须是平滑且连续的==。

深度的神奇之处在于，它将意义转换为向量，转换为几何空间，然后逐步学习将一个空间映射到另一个空间的复杂几何变换，你需要的只是维度足够大的空间去捕捉原始数据的关系。



## 12、机器学习通用的工作流程

1. 找到可用的数据，你想要预测什么，是否需要人工标注标签。
2. 找到能正确评估目标成功的方法。对于简单任务，可以使用预测精度，但很多情况下都需要与领域相关的复杂指标
3. 准备用于评估模型的验证过程。我们需要定义训练集、验证集、测试集，验证集和测试集的信息不应该提前泄露。
4. 数据向量化，将数据转换为向量并预处理，如标准化。
5. 通过调节参数和添加正则化来逐步改善模型结构，你需要先让模型过拟合，然后再添加正则化或者减小网络尺寸。
6. 调节超参数时要小心验证集过拟合，即超参数可能会过于针对验证集而优化。


